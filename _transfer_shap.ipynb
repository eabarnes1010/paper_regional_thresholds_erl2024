{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da79c16-eb43-4664-a883-7a31f3af00da",
   "metadata": {
    "id": "4a650402-4774-49cb-9b72-9c8f1dd02f1d",
    "tags": []
   },
   "source": [
    "# SHAP and Transfer Learning\n",
    "##### authors: Elizabeth A. Barnes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ccff821-b304-4009-8fe8-75a213b3f421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb968382-4186-466e-a85b-b00caa5fc9be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17642,
     "status": "ok",
     "timestamp": 1646449680995,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "fb968382-4186-466e-a85b-b00caa5fc9be",
    "outputId": "d7964af9-2d52-4466-902d-9b85faba9a91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os, copy\n",
    "import importlib as imp\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import shap\n",
    "from scipy.optimize import curve_fit\n",
    "import gc\n",
    "import plots\n",
    "import regions\n",
    "\n",
    "import regionmask\n",
    "import experiment_settings\n",
    "import file_methods, plots, data_processing, transfer_learning, xai\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy as ct\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 150\n",
    "savefig_dpi = 300\n",
    "# plt.style.use(\"seaborn-notebook\")\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")\n",
    "print(f\"tensorflow-probability version = {tfp.__version__}\")\n",
    "print(f\"shap version = {shap.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "651315ce-eecc-4d30-8b90-c97d08936315",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a544f-ef35-417f-bec4-62225d885014",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_EXP_NAME = \"exp134\"  # \"exp134\"\n",
    "EVAL_THRESHOLD = 2.0\n",
    "RESAVE = True\n",
    "\n",
    "# -------------------------------------------------------\n",
    "\n",
    "RNG_SEED = 66\n",
    "settings = experiment_settings.get_settings(PARENT_EXP_NAME)\n",
    "settings[\"target_temp\"] = EVAL_THRESHOLD\n",
    "settings[\"rng_seed\"] = RNG_SEED\n",
    "\n",
    "# -------------------------------------------------------\n",
    "\n",
    "MODEL_DIRECTORY = \"saved_models/\"\n",
    "PREDICTIONS_DIRECTORY = \"saved_predictions/\"\n",
    "DATA_DIRECTORY = (\n",
    "    \"../../../2022/target_temp_detection/data/\"  # point to where your data is sitting\n",
    ")\n",
    "GCM_DATA_DIRECTORY = \"../data/\"\n",
    "OBS_DIRECTORY = \"../data/\"\n",
    "DIAGNOSTICS_DIRECTORY = \"model_diagnostics/\"\n",
    "FIGURE_DIRECTORY = \"figures/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c072cd54",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observational data\n",
    "settings_obs = settings.copy()\n",
    "settings_obs[\"training_only\"] = True\n",
    "\n",
    "settings_obs[\"obs_training_only\"] = True\n",
    "__, x_obs, global_mean_obs = data_processing.get_observations(\n",
    "    OBS_DIRECTORY, settings_obs, verbose=False\n",
    ")\n",
    "\n",
    "settings_obs[\"obs_training_only\"] = False\n",
    "settings_obs[\"cumulative_history\"] = False\n",
    "settings_obs[\"cumulative_history_only\"] = False\n",
    "da_obs, __, __ = data_processing.get_observations(\n",
    "    OBS_DIRECTORY, settings_obs, verbose=False\n",
    ")\n",
    "mask = regionmask.defined_regions.ar6.land.mask(da_obs)\n",
    "da_obs_shape = da_obs.shape\n",
    "del da_obs\n",
    "\n",
    "# CMIP testing data\n",
    "tf.keras.utils.set_random_seed(settings[\"rng_seed\"])\n",
    "\n",
    "(\n",
    "    __,\n",
    "    __,\n",
    "    x_test,\n",
    "    __,\n",
    "    __,\n",
    "    __,\n",
    "    __,\n",
    "    __,\n",
    "    onehot_test,\n",
    "    __,\n",
    "    __,\n",
    "    y_yrs_test,\n",
    "    __,\n",
    "    __,\n",
    "    target_temps_test,\n",
    "    target_years_region,\n",
    "    map_shape,\n",
    "    __,\n",
    ") = data_processing.create_data(DATA_DIRECTORY, settings.copy(), verbose=0)\n",
    "\n",
    "# One member per GCM data\n",
    "settings_gcm = settings.copy()\n",
    "settings_gcm[\"target_region\"] = None\n",
    "settings_gcm[\"anomaly_yr_bounds\"] = settings_gcm[\"baseline_yr_bounds\"]\n",
    "cmip_data = data_processing.get_one_model_one_vote_data(\n",
    "    GCM_DATA_DIRECTORY, settings_gcm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91076893",
   "metadata": {},
   "source": [
    "## Transfer Learning Main Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ad281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import network\n",
    "imp.reload(data_processing)\n",
    "imp.reload(plots)\n",
    "imp.reload(transfer_learning)\n",
    "imp.reload(network)\n",
    "\n",
    "IPCC_REGION_LIST = regionmask.defined_regions.ar6.land.abbrevs\n",
    "\n",
    "obs_transfer_dict = {}\n",
    "obs_transfer_dict[1.5] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_transfer_dict[2.0] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_transfer_dict[3.0] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_base_dict = copy.deepcopy(obs_transfer_dict)\n",
    "\n",
    "for ireg, ipcc_region in enumerate(IPCC_REGION_LIST):\n",
    "    # if ipcc_region not in (\"WCE\", \"CNA\", \"SAH\", \"ESB\", \"NSA\", \"CAU\"):\n",
    "    #     continue\n",
    "    # if ipcc_region not in (\"WCE\",):\n",
    "    #     continue\n",
    "    if ipcc_region not in (\"CNA\",):\n",
    "        continue\n",
    "\n",
    "    # ------------------------------------\n",
    "    # SETTINGS AND MODEL SETUP\n",
    "\n",
    "    # define particular settings\n",
    "    settings[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "    settings[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "\n",
    "    settings_obs[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "    settings_obs[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "\n",
    "    settings_obs[\"obs_training_only\"] = False\n",
    "    settings_obs[\"cumulative_history\"] = False\n",
    "    settings_obs[\"cumulative_history_only\"] = False\n",
    "    da_obs, __, __ = data_processing.get_observations(\n",
    "        OBS_DIRECTORY, settings_obs, verbose=False\n",
    "    )\n",
    "    da_obs, __, __ = regions.extract_region(settings_obs, da_obs)\n",
    "\n",
    "    # load the models\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(settings_obs[\"rng_seed\"])\n",
    "\n",
    "    try:\n",
    "        model_name = file_methods.get_model_name(settings_obs)\n",
    "        model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "        transfer_model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(\"---\" + str(ireg) + \": \" + ipcc_region + \"---\")\n",
    "\n",
    "    # ------------------------------------\n",
    "    # FINE-TUNE WITH TRANSFER LEARNING\n",
    "\n",
    "    (\n",
    "        transfer_model,\n",
    "        obs_timeseries,\n",
    "        obs_years,\n",
    "        obs_yearsvals_dict,\n",
    "    ) = transfer_learning.perform_transfer_learning(\n",
    "        transfer_model, da_obs, x_obs, settings_obs, plot=False\n",
    "    )\n",
    "\n",
    "    obs_base_dict = transfer_learning.compute_threshold_predictions(\n",
    "        obs_base_dict, ireg, model, x_obs\n",
    "    )\n",
    "    obs_transfer_dict = transfer_learning.compute_threshold_predictions(\n",
    "        obs_transfer_dict, ireg, transfer_model, x_obs\n",
    "    )\n",
    "\n",
    "    # plot the transfer learning results\n",
    "    cmip_masked_region = xr.where(mask == ireg, cmip_data, np.nan).transpose(\n",
    "        \"gcm\", \"time\", \"lat\", \"lon\"\n",
    "    )\n",
    "    plots.plot_transferlearning_timeseries(\n",
    "        model,\n",
    "        transfer_model,\n",
    "        x_obs,\n",
    "        obs_timeseries,\n",
    "        obs_years,\n",
    "        obs_yearsvals_dict,\n",
    "        cmip_masked_region,\n",
    "        settings,\n",
    "        title=ipcc_region,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plots.savefig(\n",
    "        FIGURE_DIRECTORY + model_name + \"_transfer_learning\",\n",
    "        dpi=savefig_dpi,\n",
    "    )\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    # continue\n",
    "\n",
    "    # ------------------------------------\n",
    "    # CLEAR BIG THINGS\n",
    "    try:\n",
    "        del (da_obs,)\n",
    "        _ = gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # ------------------------------------\n",
    "    # SAVE THE TRANSFER LEARNING DATA\n",
    "    if RESAVE:\n",
    "        filename = (\n",
    "            PREDICTIONS_DIRECTORY\n",
    "            + PARENT_EXP_NAME\n",
    "            + \"_rng_seed\"\n",
    "            + str(settings_obs[\"rng_seed\"])\n",
    "            + \"_observations_\"\n",
    "            + str(settings[\"final_year_of_obs\"])\n",
    "            + \"_predictions_base.pickle\"\n",
    "        )\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [\n",
    "                    obs_base_dict,\n",
    "                ],\n",
    "                f,\n",
    "            )\n",
    "\n",
    "        filename = (\n",
    "            PREDICTIONS_DIRECTORY\n",
    "            + PARENT_EXP_NAME\n",
    "            + \"_rng_seed\"\n",
    "            + str(settings_obs[\"rng_seed\"])\n",
    "            + \"_observations_\"\n",
    "            + str(settings[\"final_year_of_obs\"])\n",
    "            + \"_predictions_transfer.pickle\"\n",
    "        )\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [\n",
    "                    obs_transfer_dict,\n",
    "                ],\n",
    "                f,\n",
    "            )\n",
    "        # print(\"data saved.\")\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866628d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07eb3a",
   "metadata": {},
   "source": [
    "## Transfer Learning Schematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(data_processing)\n",
    "imp.reload(plots)\n",
    "imp.reload(transfer_learning)\n",
    "\n",
    "IPCC_REGION_LIST = regionmask.defined_regions.ar6.land.abbrevs\n",
    "\n",
    "obs_transfer_dict = {}\n",
    "obs_transfer_dict[1.5] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_transfer_dict[2.0] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_transfer_dict[3.0] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_base_dict = copy.deepcopy(obs_transfer_dict)\n",
    "\n",
    "for ireg, ipcc_region in enumerate(IPCC_REGION_LIST):\n",
    "    if ipcc_region not in (\"WCE\",):\n",
    "        continue\n",
    "\n",
    "    # ------------------------------------\n",
    "    # SETTINGS AND MODEL SETUP\n",
    "\n",
    "    # define particular settings\n",
    "    settings[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "    settings[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "\n",
    "    settings_obs[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "    settings_obs[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "\n",
    "    settings_obs[\"obs_training_only\"] = False\n",
    "    settings_obs[\"cumulative_history\"] = False\n",
    "    settings_obs[\"cumulative_history_only\"] = False\n",
    "    da_obs, __, __ = data_processing.get_observations(\n",
    "        OBS_DIRECTORY, settings_obs, verbose=False\n",
    "    )\n",
    "    da_obs, __, __ = regions.extract_region(settings_obs, da_obs)\n",
    "\n",
    "    # load the models\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(settings_obs[\"rng_seed\"])\n",
    "\n",
    "    try:\n",
    "        model_name = file_methods.get_model_name(settings_obs)\n",
    "        model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "        transfer_model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(\"---\" + str(ireg) + \": \" + ipcc_region + \"---\")\n",
    "\n",
    "    # ------------------------------------\n",
    "    # FINE-TUNE WITH TRANSFER LEARNING\n",
    "\n",
    "    (\n",
    "        transfer_model,\n",
    "        obs_timeseries,\n",
    "        obs_years,\n",
    "        obs_yearsvals_dict,\n",
    "    ) = transfer_learning.perform_transfer_learning(\n",
    "        transfer_model, da_obs, x_obs, settings_obs, plot=True\n",
    "    )\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee81c03",
   "metadata": {},
   "source": [
    "## Transfer Learning on only 3 temperature thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c95098",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(data_processing)\n",
    "imp.reload(plots)\n",
    "imp.reload(transfer_learning)\n",
    "\n",
    "EXP_SUFFIX = \"_3thresholds\"\n",
    "IPCC_REGION_LIST = regionmask.defined_regions.ar6.land.abbrevs\n",
    "\n",
    "obs_transfer_dict = {}\n",
    "obs_transfer_dict[1.5] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_transfer_dict[2.0] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_transfer_dict[3.0] = np.zeros((len(IPCC_REGION_LIST), 2)) * np.nan\n",
    "obs_base_dict = copy.deepcopy(obs_transfer_dict)\n",
    "\n",
    "for ireg, ipcc_region in enumerate(IPCC_REGION_LIST):\n",
    "    # ------------------------------------\n",
    "    # SETTINGS AND MODEL SETUP\n",
    "\n",
    "    # define particular settings\n",
    "    settings[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "    settings[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "    settings[\"transfer_temp_vec\"] = (0.8, 1.0, 1.2)\n",
    "\n",
    "    settings_obs[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "    settings_obs[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "    settings_obs[\"transfer_temp_vec\"] = settings[\"transfer_temp_vec\"]\n",
    "\n",
    "    settings_obs[\"obs_training_only\"] = False\n",
    "    settings_obs[\"cumulative_history\"] = False\n",
    "    settings_obs[\"cumulative_history_only\"] = False\n",
    "    da_obs, __, __ = data_processing.get_observations(\n",
    "        OBS_DIRECTORY, settings_obs, verbose=False\n",
    "    )\n",
    "    da_obs, __, __ = regions.extract_region(settings_obs, da_obs)\n",
    "\n",
    "    # load the models\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(settings_obs[\"rng_seed\"])\n",
    "\n",
    "    try:\n",
    "        model_name = file_methods.get_model_name(settings_obs)\n",
    "        model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "        transfer_model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(\"---\" + str(ireg) + \": \" + ipcc_region + \"---\")\n",
    "\n",
    "    # ------------------------------------\n",
    "    # FINE-TUNE WITH TRANSFER LEARNING\n",
    "\n",
    "    (\n",
    "        transfer_model,\n",
    "        obs_timeseries,\n",
    "        obs_years,\n",
    "        obs_yearsvals_dict,\n",
    "    ) = transfer_learning.perform_transfer_learning(\n",
    "        transfer_model, da_obs, x_obs, settings_obs, plot=False, suffix=EXP_SUFFIX\n",
    "    )\n",
    "\n",
    "    obs_base_dict = transfer_learning.compute_threshold_predictions(\n",
    "        obs_base_dict, ireg, model, x_obs\n",
    "    )\n",
    "    obs_transfer_dict = transfer_learning.compute_threshold_predictions(\n",
    "        obs_transfer_dict, ireg, transfer_model, x_obs\n",
    "    )\n",
    "\n",
    "    # plot the transfer learning results\n",
    "    cmip_masked_region = xr.where(mask == ireg, cmip_data, np.nan).transpose(\n",
    "        \"gcm\", \"time\", \"lat\", \"lon\"\n",
    "    )\n",
    "    plots.plot_transferlearning_timeseries(\n",
    "        model,\n",
    "        transfer_model,\n",
    "        x_obs,\n",
    "        obs_timeseries,\n",
    "        obs_years,\n",
    "        obs_yearsvals_dict,\n",
    "        cmip_masked_region,\n",
    "        settings,\n",
    "        title=ipcc_region,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plots.savefig(\n",
    "        FIGURE_DIRECTORY + model_name + \"_transfer_learning\" + EXP_SUFFIX,\n",
    "        dpi=savefig_dpi,\n",
    "    )\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------\n",
    "    # CLEAR BIG THINGS\n",
    "    try:\n",
    "        del (da_obs,)\n",
    "        _ = gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # ------------------------------------\n",
    "    # SAVE THE TRANSFER LEARNING DATA\n",
    "    if RESAVE:\n",
    "        filename = (\n",
    "            PREDICTIONS_DIRECTORY\n",
    "            + PARENT_EXP_NAME\n",
    "            + \"_rng_seed\"\n",
    "            + str(settings_obs[\"rng_seed\"])\n",
    "            + \"_observations_\"\n",
    "            + str(settings[\"final_year_of_obs\"])\n",
    "            + \"_predictions_base\"\n",
    "            + EXP_SUFFIX\n",
    "            + \".pickle\"\n",
    "        )\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [\n",
    "                    obs_base_dict,\n",
    "                ],\n",
    "                f,\n",
    "            )\n",
    "\n",
    "        filename = (\n",
    "            PREDICTIONS_DIRECTORY\n",
    "            + PARENT_EXP_NAME\n",
    "            + \"_rng_seed\"\n",
    "            + str(settings_obs[\"rng_seed\"])\n",
    "            + \"_observations_\"\n",
    "            + str(settings[\"final_year_of_obs\"])\n",
    "            + \"_predictions_transfer\"\n",
    "            + EXP_SUFFIX\n",
    "            + \".pickle\"\n",
    "        )\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [\n",
    "                    obs_transfer_dict,\n",
    "                ],\n",
    "                f,\n",
    "            )\n",
    "        # print(\"data saved.\")\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7429e",
   "metadata": {},
   "source": [
    "## XAI with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(xai)\n",
    "imp.reload(plots)\n",
    "\n",
    "tf.config.set_visible_devices(\n",
    "    [], \"GPU\"\n",
    ")  # DO NOT TURN ON THE GPU! There are issues with DEEPSHAP!\n",
    "\n",
    "# get the data put together for deep-shap, including the baseline\n",
    "xai_settings = {\n",
    "    \"obs_start\": 2000,\n",
    "    \"obs_end\": settings[\"final_year_of_obs\"],\n",
    "    \"baseline_factor\": 0.0,\n",
    "    \"baseline_start\": 2000,\n",
    "    \"baseline_end\": 2000,\n",
    "    \"n_base_samples\": 1,\n",
    "    \"n_cmip_samples\": None,\n",
    "    \"target_temp\": settings[\"target_temp\"],\n",
    "    \"rng_seed_list\": settings[\"rng_seed_list\"],\n",
    "    \"rng_seed_list\": (66,),\n",
    "    # \"rng_seed\": None,\n",
    "    \"diff_scaling\": 0.2,\n",
    "}\n",
    "\n",
    "IPCC_REGION_LIST = regionmask.defined_regions.ar6.land.abbrevs\n",
    "\n",
    "for ireg, ipcc_region in enumerate(IPCC_REGION_LIST):\n",
    "    if ipcc_region not in (\"WCE\", \"CNA\", \"SAH\", \"ESB\", \"NSA\", \"CAU\"):\n",
    "        continue\n",
    "    # if ipcc_region not in (\"WCE\",):\n",
    "    #     continue\n",
    "\n",
    "    print(\"---\" + str(ireg) + \": \" + ipcc_region + \"---\")\n",
    "\n",
    "    original_shap_seeds = np.zeros(da_obs_shape[1:])\n",
    "    transfer_shap_seeds = np.zeros(da_obs_shape[1:])\n",
    "    cmip_shap_seeds = np.zeros(da_obs_shape[1:])\n",
    "\n",
    "    for seed in xai_settings[\"rng_seed_list\"]:\n",
    "        xai_settings[\"rng_seed\"] = seed\n",
    "\n",
    "        # ------------------------------------\n",
    "        # SETTINGS AND MODEL SETUP\n",
    "\n",
    "        # define particular settings\n",
    "        settings[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "        settings[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "        settings[\"rng_seed\"] = xai_settings[\"rng_seed\"]\n",
    "\n",
    "        settings_obs[\"target_region\"] = \"ipcc_\" + ipcc_region\n",
    "        settings_obs[\"exp_name\"] = PARENT_EXP_NAME + \"_\" + ipcc_region\n",
    "        settings_obs[\"rng_seed\"] = xai_settings[\"rng_seed\"]\n",
    "\n",
    "        settings_obs[\"obs_training_only\"] = False\n",
    "        settings_obs[\"cumulative_history\"] = False\n",
    "        settings_obs[\"cumulative_history_only\"] = False\n",
    "        da_obs, __, __ = data_processing.get_observations(\n",
    "            OBS_DIRECTORY, settings_obs, verbose=False\n",
    "        )\n",
    "        x_obs_years = da_obs[\"time.year\"].to_numpy()[-x_obs.shape[0] :]\n",
    "\n",
    "        # load the models\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.keras.utils.set_random_seed(settings_obs[\"rng_seed\"])\n",
    "\n",
    "        model_name = file_methods.get_model_name(settings_obs)\n",
    "        model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "        print(model_name)\n",
    "\n",
    "        transfer_model_name = file_methods.get_model_name(settings) + \"_transfer\"\n",
    "        transfer_model = file_methods.load_tf_model(\n",
    "            transfer_model_name, MODEL_DIRECTORY\n",
    "        )\n",
    "        print(transfer_model_name)\n",
    "\n",
    "        (\n",
    "            original_shap,\n",
    "            transfer_shap,\n",
    "            cmip_shap,\n",
    "            expected_value,\n",
    "            expected_value_transfer,\n",
    "        ) = xai.calculate_shap_values(\n",
    "            model,\n",
    "            transfer_model,\n",
    "            x_obs,\n",
    "            x_obs_years,\n",
    "            x_test,\n",
    "            y_yrs_test,\n",
    "            xai_settings,\n",
    "            baseline_factor=xai_settings[\"baseline_factor\"],\n",
    "        )\n",
    "\n",
    "        # just add shap maps together\n",
    "        original_shap_seeds = original_shap_seeds + original_shap[0][0][\n",
    "            :, :, :, 0\n",
    "        ].mean(axis=0)\n",
    "        transfer_shap_seeds = transfer_shap_seeds + transfer_shap[0][0][\n",
    "            :, :, :, 0\n",
    "        ].mean(axis=0)\n",
    "        cmip_shap_seeds = cmip_shap_seeds + cmip_shap[0][0][:, :, :, 0].mean(axis=0)\n",
    "\n",
    "        # rescale by max value before adding together\n",
    "        # original_shap_seeds = original_shap_seeds + original_shap[0][0][:, :, :, 0].mean(axis=0) / np.abs(np.min(original_shap[0][0][:, ilat, :, 0].mean(axis=0)))\n",
    "        # transfer_shap_seeds = transfer_shap_seeds + transfer_shap[0][0][:, :, :, 0].mean(axis=0) / np.abs(np.min(transfer_shap[0][0][:, ilat, :, 0].mean(axis=0)))\n",
    "        # cmip_shap_seeds = cmip_shap_seeds + cmip_shap[0][0][:, :, :, 0].mean(axis=0) / np.abs(np.min(cmip_shap[0][0][:, ilat, :, 0].mean(axis=0)))\n",
    "\n",
    "    # CREATE THE PLOT\n",
    "    ilat = np.where(np.abs(da_obs.lat) < 60)[0]  # used for scaling\n",
    "\n",
    "    plots.plot_xai_heatmaps(\n",
    "        original_shap_seeds,\n",
    "        transfer_shap_seeds,\n",
    "        cmip_shap_seeds,\n",
    "        da_obs.lat,\n",
    "        da_obs.lon,\n",
    "        ipcc_region,\n",
    "        subplots=2,\n",
    "        scaling = 1e3 / np.abs(expected_value[0]),\n",
    "        # scaling=1. / (np.abs(np.min(original_shap_seeds[ilat, :]))*.7),\n",
    "        diff_scaling=xai_settings[\"diff_scaling\"],\n",
    "        # title=f\"\\n{model_name} {xai_settings['target_temp']}C\\n{xai_settings['obs_start']}-{xai_settings['obs_end']}\",\n",
    "        title=None,\n",
    "        colorbar=False,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plots.savefig(\n",
    "        FIGURE_DIRECTORY + model_name + \"_shap_values_2subplots\",\n",
    "        dpi=savefig_dpi,\n",
    "    )\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "    # break\n",
    "print(\"done.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
